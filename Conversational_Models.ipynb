{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7c90dba-9fbe-42bf-9aff-5d01dca16f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "You passed along `num_labels=1` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
      "Some weights of the model checkpoint at gorkemgoknar/gpt2chatbotenglish were not used when initializing GPT2LMHeadModel: ['multiple_choice_head.summary.bias', 'multiple_choice_head.summary.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "You passed along `num_labels=1` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0f72fd0aab424fb78dadf71b9b0f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/903 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960c05e061ad43e383ab0dd9eed92940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09ed8f6d4804a59b739d25cae69f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e77f90060434d15ba0c5ef419a6db40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486c3280a1a6405ab439665bdb2d0532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fd0ee700f34a1ca277ef8d5ed2e6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6175c88a1bd742829490f93dbcf5139e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7b4651e61a4c0b8dfecc66f64b14e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: microsoft/DialoGPT-small\n",
      "ROUGE-N Score: 0.1353\n",
      "ROUGE-L Score: 0.0902\n",
      "F1 Score: 0.1364\n",
      "Average Response Length: 6.800\n",
      "Model: microsoft/DialoGPT-medium\n",
      "ROUGE-N Score: 0.1974\n",
      "ROUGE-L Score: 0.1506\n",
      "F1 Score: 0.1612\n",
      "Average Response Length: 16.600\n",
      "Model: gorkemgoknar/gpt2chatbotenglish\n",
      "ROUGE-N Score: 0.1694\n",
      "ROUGE-L Score: 0.1361\n",
      "F1 Score: 0.1480\n",
      "Average Response Length: 24.000\n",
      "Model: Vaibhav-rm/GPT2-Shri-v1\n",
      "ROUGE-N Score: 0.1571\n",
      "ROUGE-L Score: 0.1048\n",
      "F1 Score: 0.1571\n",
      "Average Response Length: 4.400\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "conversational_models = [\n",
    "    'microsoft/DialoGPT-small',\n",
    "    'microsoft/DialoGPT-medium',\n",
    "    'gorkemgoknar/gpt2chatbotenglish',\n",
    "    'Vaibhav-rm/GPT2-Shri-v1'\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "    \"How does photosynthesis work?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain the theory of relativity.\",\n",
    "    \"Any book recommendations?\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll.\",\n",
    "    \"Why did the chicken cross the road? To get to the other side!\",\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"The theory of relativity, formulated by Albert Einstein, describes the relationships between space, time, and gravity.\",\n",
    "    \"It depends on your interests. What genres do you like?\"\n",
    "]\n",
    "\n",
    "def initialize_model_and_tokenizer(model_name):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=50, temperature=0.7):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, num_beams=5)\n",
    "    generated_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_response\n",
    "\n",
    "\n",
    "\n",
    "def calculate_rouge(reference, candidate):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(candidate, reference)\n",
    "    rouge_n_score = scores[0]['rouge-1']['f']\n",
    "    rouge_l_score = scores[0]['rouge-l']['f']\n",
    "    return rouge_n_score, rouge_l_score\n",
    "\n",
    "\n",
    "\n",
    "def calculate_f1(reference, candidate):\n",
    "    reference_set = set(reference.split())\n",
    "    candidate_set = set(candidate.split())\n",
    "\n",
    "    precision = len(reference_set.intersection(candidate_set)) / len(candidate_set)\n",
    "    recall = len(reference_set.intersection(candidate_set)) / len(reference_set)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "results = dict()\n",
    "\n",
    "\n",
    "for model_name in conversational_models:\n",
    "    model, tokenizer = initialize_model_and_tokenizer(model_name)\n",
    "    \n",
    "    rouge_n_scores = []\n",
    "    rouge_l_scores = []\n",
    "    f1_scores = []\n",
    "    response_lengths = []\n",
    "\n",
    "    for prompt, reference in zip(prompts, references):\n",
    "        model_response = generate_response(prompt, model, tokenizer)\n",
    "\n",
    "       \n",
    "        rouge_n_score, rouge_l_score = calculate_rouge(reference, model_response)\n",
    "        rouge_n_scores.append(rouge_n_score)\n",
    "        rouge_l_scores.append(rouge_l_score)\n",
    "\n",
    "\n",
    "       \n",
    "        f1 = calculate_f1(reference, model_response)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        response_lengths.append(len(model_response.split()))\n",
    "\n",
    "    \n",
    "    avg_rouge_n_score = sum(rouge_n_scores) / len(rouge_n_scores)\n",
    "    avg_rouge_l_score = sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "    avg_f1_score = sum(f1_scores)/len(f1_scores)\n",
    "    avg_response_length = sum(response_lengths) / len(response_lengths)\n",
    "\n",
    "       \n",
    "\n",
    "            \n",
    "\n",
    "    results[model_name] = {\n",
    "            \n",
    "            \"ROUGE-N\": avg_rouge_n_score,\n",
    "            \"ROUGE-L\": avg_rouge_l_score,\n",
    "            \"F1\" : avg_f1_score,\n",
    "            \"Response Length\": avg_response_length\n",
    "        }\n",
    "\n",
    "for model_name, scores in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"ROUGE-N Score: {scores['ROUGE-N']:.4f}\")\n",
    "    print(f\"ROUGE-L Score: {scores['ROUGE-L']:.4f}\")\n",
    "    print(f\"F1 Score: {scores['F1']:.4f}\")\n",
    "    print(f\"Average Response Length: {scores['Response Length']:.3f}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21240258-2926-4f1b-9df3-5e401918bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE-N</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>F1</th>\n",
       "      <th>Response Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>microsoft/DialoGPT-small</th>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft/DialoGPT-medium</th>\n",
       "      <td>0.197403</td>\n",
       "      <td>0.150649</td>\n",
       "      <td>0.161212</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gorkemgoknar/gpt2chatbotenglish</th>\n",
       "      <td>0.169444</td>\n",
       "      <td>0.136111</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaibhav-rm/GPT2-Shri-v1</th>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ROUGE-N   ROUGE-L        F1  Response Length\n",
       "microsoft/DialoGPT-small         0.135294  0.090196  0.136364              6.8\n",
       "microsoft/DialoGPT-medium        0.197403  0.150649  0.161212             16.6\n",
       "gorkemgoknar/gpt2chatbotenglish  0.169444  0.136111  0.148000             24.0\n",
       "Vaibhav-rm/GPT2-Shri-v1          0.157143  0.104762  0.157143              4.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d81f0a7-56e5-4dac-90c8-e7faab1e9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('Topsis_input.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
